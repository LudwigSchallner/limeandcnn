{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.models import model_from_json\n",
    "from datetime import datetime\n",
    "from keras.applications import inception_v3 as inc_net\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalMaxPooling2D \n",
    "from keras.models import load_model\n",
    "from keras.callbacksTest import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam, Adamax\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 299\n",
    "my_epochs_basic = 3\n",
    "my_epochs_retrain = 11\n",
    "is_shuffle = True\n",
    "write_batch_per = True\n",
    "\n",
    "data_type = 'flowers'\n",
    "prefix = ''\n",
    "if(data_type == 'mushrooms128'):\n",
    "    num_classes = 128\n",
    "    my_batch_size = 128\n",
    "    my_steps_per_epoch = 850\n",
    "    my_val_steps = 18\n",
    "elif(data_type == 'mushrooms24'):\n",
    "    num_classes = 24\n",
    "    my_batch_size = 64\n",
    "    my_steps_per_epoch = 376\n",
    "    my_val_steps = 18\n",
    "elif(data_type == 'flowers'):\n",
    "    num_classes = 5\n",
    "    my_batch_size = 16\n",
    "    my_steps_per_epoch = 188\n",
    "    my_val_steps = 42\n",
    "elif(data_type == 'tabak'):\n",
    "    num_classes = 2\n",
    "    my_batch_size = 16\n",
    "    my_steps_per_epoch = 40\n",
    "    my_val_steps = 4\n",
    "    my_epochs_basic = 3\n",
    "    my_epochs_retrain = 30\n",
    "    \n",
    "data_path_train = os.path.join('data',data_type,'train')\n",
    "data_path_test = os.path.join('data',data_type,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model Loaded'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD BASE MODEL \n",
    "base_model = inc_net.InceptionV3(weights='imagenet', include_top=False)\n",
    "'Model Loaded'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 5 classes.\n",
      "Found 670 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#train / test data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range = 0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set= train_datagen.flow_from_directory(data_path_train,\n",
    "                                                target_size = (img_size, img_size),\n",
    "                                                batch_size=my_batch_size,\n",
    "                                                class_mode='categorical')\n",
    "val_set = test_datagen.flow_from_directory(data_path_test,\n",
    "                                           target_size= (img_size, img_size),\n",
    "                                           batch_size=my_batch_size,\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntop_model = Sequential()\\n#top_model.add(Flatten(input_shape=base_model.output_shape[1:])) obsolet because include_top=False = includes a flatten\\n#output_shape[1:] because else we get 5 dimension but we need 4\\ntop_model.add(Dense(1024, activation='relu', input_shape=base_model.output_shape[1:]))\\ntop_model.add(MaxPooling2D(pool_size=(2, 2)))\\ntop_model.add(Dropout(0.5))\\ntop_model.add(Dense(1024, activation='relu'))\\n#top_model.load_weights('InceptionV3_weights.h5')\\ntop_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\\ntop_model.fit_generator(training_set)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "#top_model.add(Flatten(input_shape=base_model.output_shape[1:])) obsolet because include_top=False = includes a flatten\n",
    "#output_shape[1:] because else we get 5 dimension but we need 4\n",
    "top_model.add(Dense(1024, activation='relu', input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "#top_model.load_weights('InceptionV3_weights.h5')\n",
    "top_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "top_model.fit_generator(training_set)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have num_classes classes\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "#freezing all layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "188/188 [==============================] - 119s 633ms/step - loss: 1.9271 - acc: 0.5974 - val_loss: 1.1039 - val_acc: 0.6328\n",
      "Epoch 2/3\n",
      "188/188 [==============================] - 74s 391ms/step - loss: 0.6698 - acc: 0.7566 - val_loss: 2.0100 - val_acc: 0.5164\n",
      "Epoch 3/3\n",
      "188/188 [==============================] - 76s 404ms/step - loss: 0.5735 - acc: 0.8002 - val_loss: 1.5495 - val_acc: 0.5701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f18509c18>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_of_test = str(datetime.now().strftime(\"%d-%m-%y %H%M\"))\n",
    "file_name= prefix+time_of_test+'_Epochs'+str(my_epochs_basic)+'_ImageSize'+str(img_size)+'_BatchSize'+str(my_batch_size)\n",
    "\n",
    "log_path = os.path.join('logs',data_type,'pretrain','')\n",
    "model_path = os.path.join('trainedModels',data_type,'pretrain','')\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "                    steps_per_epoch=my_steps_per_epoch,\n",
    "                    epochs=my_epochs_basic,\n",
    "                    validation_data=val_set,\n",
    "                    validation_steps=my_val_steps,\n",
    "                    shuffle=is_shuffle,\n",
    "                    callbacks=[\n",
    "                        TensorBoard(\n",
    "                            log_dir=log_path,\n",
    "                            write_batch_performance=write_batch_per)]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainedModels/flowers/pretrain/16-10-18 1751_Epochs3_ImageSize299_BatchSize16.h5\n",
      "Saved model to disk as> 16-10-18 1751_Epochs3_ImageSize299_BatchSize16\n"
     ]
    }
   ],
   "source": [
    "# SAVE THE CURRENT MODEL\n",
    "print(model_path+file_name+'.h5')\n",
    "model.save(model_path+file_name+'.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "print(\"Saved model to disk as> \"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded> 16-10-18 1751_Epochs3_ImageSize299_BatchSize16\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE CURRENT MODEL\n",
    "#file_name= '16-07-18 15:22_Epochs3_Steps40_ImageSize299_BatchSize16'\n",
    "model = load_model(model_path+file_name+'.h5')\n",
    "print('Model loaded> '+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbCallBack_finetune = TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "\n",
    "#model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "188/188 [==============================] - 87s 461ms/step - loss: 0.4454 - acc: 0.8597 - val_loss: 0.5664 - val_acc: 0.8433\n",
      "Epoch 2/11\n",
      "188/188 [==============================] - 76s 407ms/step - loss: 0.2237 - acc: 0.9282 - val_loss: 0.9050 - val_acc: 0.8045\n",
      "Epoch 3/11\n",
      "188/188 [==============================] - 78s 416ms/step - loss: 0.1631 - acc: 0.9488 - val_loss: 0.4428 - val_acc: 0.8836\n",
      "Epoch 4/11\n",
      "188/188 [==============================] - 78s 415ms/step - loss: 0.1283 - acc: 0.9585 - val_loss: 0.6006 - val_acc: 0.8597\n",
      "\n",
      "Epoch 00004: saving model to ./ModelCheckpoints/16-10-18 1756__weights.04-val_acc0.86--train_acc0.96.hdf5\n",
      "Epoch 5/11\n",
      "188/188 [==============================] - 76s 405ms/step - loss: 0.1009 - acc: 0.9681 - val_loss: 1.1465 - val_acc: 0.7925\n",
      "Epoch 6/11\n",
      "188/188 [==============================] - 80s 427ms/step - loss: 0.0844 - acc: 0.9741 - val_loss: 0.6613 - val_acc: 0.8597\n",
      "Epoch 7/11\n",
      "188/188 [==============================] - 80s 424ms/step - loss: 0.0804 - acc: 0.9721 - val_loss: 0.6765 - val_acc: 0.8537\n",
      "Epoch 8/11\n",
      "188/188 [==============================] - 78s 416ms/step - loss: 0.0723 - acc: 0.9767 - val_loss: 0.5217 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00008: saving model to ./ModelCheckpoints/16-10-18 1756__weights.08-val_acc0.89--train_acc0.98.hdf5\n",
      "Epoch 9/11\n",
      "188/188 [==============================] - 76s 407ms/step - loss: 0.0567 - acc: 0.9791 - val_loss: 0.6044 - val_acc: 0.8791\n",
      "Epoch 10/11\n",
      "188/188 [==============================] - 79s 418ms/step - loss: 0.0443 - acc: 0.9850 - val_loss: 0.6227 - val_acc: 0.8672\n",
      "Epoch 11/11\n",
      "188/188 [==============================] - 80s 423ms/step - loss: 0.0502 - acc: 0.9820 - val_loss: 0.6078 - val_acc: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f182a7208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_of_real = str(datetime.now().strftime(\"%d-%m-%y %H%M\"))\n",
    "file_name = prefix+time_of_real+'__Epochs'+str(my_epochs_retrain)+'_ImageSize'+str(img_size)+'_BatchSize'+str(my_batch_size)\n",
    "log_path = os.path.join('logs',data_type,'completetrain','')\n",
    "#model.load_weights('./ModelCheckpoints/26-06-18 16:15__weights.11-2.52.hdf5')\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "\n",
    "    \n",
    "model.fit_generator(training_set,\n",
    "                    steps_per_epoch=my_steps_per_epoch,\n",
    "                    epochs=my_epochs_retrain, \n",
    "                    validation_data=val_set,\n",
    "                    validation_steps=my_val_steps,\n",
    "                    shuffle=is_shuffle,\n",
    "                    #initial_epoch=10,\n",
    "                    callbacks=[TensorBoard(log_dir=log_path,\n",
    "                                           write_batch_performance=write_batch_per),\n",
    "                              ModelCheckpoint('./ModelCheckpoints/'\n",
    "                                              +time_of_real\n",
    "                                              +'__weights.{epoch:02d}-val_acc{val_acc:.2f}--train_acc{acc:.2f}.hdf5',\n",
    "                                              monitor='val_loss',\n",
    "                                              verbose=1,\n",
    "                                              save_best_only=False,\n",
    "                                              save_weights_only=False,\n",
    "                                              mode='auto',\n",
    "                                              period=4)\n",
    "                              ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to save modeltrainedModels/flowers/completetrain/16-10-18 1756__Epochs11_ImageSize299_BatchSize16.h5\n",
      "Saved model to disk as> 16-10-18 1756__Epochs11_ImageSize299_BatchSize16\n"
     ]
    }
   ],
   "source": [
    "## SAVE THE MODEL\n",
    "model_path = os.path.join('trainedModels',data_type,'completetrain','')\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "print('try to save model'+\n",
    "      model_path+file_name+'.h5')\n",
    "model.save( model_path+file_name+'.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "print(\"Saved model to disk as> \"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "masterarbeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
