{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.models import model_from_json\n",
    "from datetime import datetime\n",
    "from keras.applications import inception_v3 as inc_net\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacksTest import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1058 images belonging to 2 classes.\n",
      "Found 71 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#train / test data\n",
    "data_type = 'tabak'\n",
    "img_size = 299\n",
    "my_batch_size = 16\n",
    "my_epoch = 9\n",
    "\n",
    "\n",
    "log_path = os.path.join('logs',data_type,'own','')\n",
    "model_path = os.path.join('trainedModels',data_type,'own','')\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "data_path_train = os.path.join('data',data_type,'train')\n",
    "data_path_test = os.path.join('data',data_type,'test')\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range = 0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set= train_datagen.flow_from_directory(data_path_train,\n",
    "                                                target_size = (img_size, img_size),\n",
    "                                                batch_size=my_batch_size,\n",
    "                                                class_mode='categorical')\n",
    "val_set = test_datagen.flow_from_directory(data_path_test,\n",
    "                                           target_size= (img_size, img_size),\n",
    "                                           batch_size=my_batch_size,\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "67/67 [==============================] - 55s 819ms/step - loss: 0.6408 - acc: 0.6632 - val_loss: 0.5563 - val_acc: 0.7465\n",
      "Epoch 2/9\n",
      "67/67 [==============================] - 53s 792ms/step - loss: 0.4177 - acc: 0.8227 - val_loss: 0.1817 - val_acc: 0.9437\n",
      "Epoch 3/9\n",
      "67/67 [==============================] - 53s 796ms/step - loss: 0.2788 - acc: 0.8936 - val_loss: 0.1839 - val_acc: 0.9437\n",
      "Epoch 4/9\n",
      "67/67 [==============================] - 53s 794ms/step - loss: 0.2095 - acc: 0.9207 - val_loss: 0.1239 - val_acc: 0.9437\n",
      "Epoch 5/9\n",
      "67/67 [==============================] - 54s 804ms/step - loss: 0.2215 - acc: 0.9272 - val_loss: 0.1524 - val_acc: 0.9437\n",
      "Epoch 6/9\n",
      "67/67 [==============================] - 53s 793ms/step - loss: 0.1718 - acc: 0.9347 - val_loss: 0.1583 - val_acc: 0.9437\n",
      "Epoch 7/9\n",
      "67/67 [==============================] - 54s 801ms/step - loss: 0.1709 - acc: 0.9431 - val_loss: 0.1753 - val_acc: 0.9437\n",
      "Epoch 8/9\n",
      "67/67 [==============================] - 54s 804ms/step - loss: 0.1495 - acc: 0.9524 - val_loss: 0.1356 - val_acc: 0.9437\n",
      "Epoch 9/9\n",
      "67/67 [==============================] - 54s 800ms/step - loss: 0.1165 - acc: 0.9561 - val_loss: 0.2912 - val_acc: 0.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f165eda4f98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "first_filter = 64\n",
    "model.add(Conv2D(first_filter,(3,3), activation='relu', input_shape=(299,299,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "second_filter = first_filter*2\n",
    "#1 hidden\n",
    "model.add(Conv2D(second_filter,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#2 hidden\n",
    "model.add(Conv2D(second_filter,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#3 hidden\n",
    "model.add(Conv2D(second_filter,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#4 hidden\n",
    "model.add(Conv2D(second_filter,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#5 hidden\n",
    "model.add(Conv2D(second_filter,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'] )\n",
    "model.fit_generator(training_set,\n",
    "                    #steps_per_epoch=my_steps_per_epoch,\n",
    "                    epochs=my_epoch,\n",
    "                    validation_data=val_set,\n",
    "                    #validation_steps=my_val_steps,\n",
    "                    #shuffle=is_shuffle,\n",
    "                \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk as> 01-08-18 18:15_Epochs9_ImageSize299_BatchSize16\n"
     ]
    }
   ],
   "source": [
    "file_name= str(datetime.now().strftime(\"%d-%m-%y %H:%M\"))+'_Epochs'+str(my_epoch)+'_ImageSize'+str(img_size)+'_BatchSize'+str(my_batch_size)\n",
    "model.save(model_path+file_name+'.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "print(\"Saved model to disk as> \"+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
